# 视频格式

## 本文大部分参考了

~~http://vcb-s.com/archives/2726~~



## 视频的基础参数

### 分辨率

视频是由连续的图像构成的。每一张图像，我们称为一 **帧(frame)** 。图像则是由像素(pixel)构成的。一张图像有多少像素，称为这个图像的 **分辨率**。比如说1920×1080的图像，说明它是由横纵1920×1080个像素点构成。视频的分辨率就是每一帧图像的分辨率。

### 帧率

一个视频，每一秒由多少图像构成，称为这个视频的 **帧率(frame-rate)** 。常见的帧率有24000/1001=23.976, 30000/1001=29.970, 60000/1001=59.940, 25.000, 50.000等等。这个数字是一秒钟内闪过的图像的数量。比如23.976，就是1001秒内，有24000张图像。视频的帧率是可以是恒定的(cfr, Const Frame-Rate)，也可以是变化的(vfr, Variable Frame-Rate)

### 码率

**码率** 的定义是视频文件体积除以时间。单位一般是Kbps(Kbit/s)或者Mbps(Mbit/s)。注意1B(Byte)=8b(bit)。所以一个24分钟，900MB的视频：

体积：900MB = 900MByte = 7200Mbit

时间：24min = 1440s

码率：7200/1440  = 5000 Kbps = 5Mbps

当视频文件的时间基本相同的时候（比如现在一集番大概是24分钟），码率和体积基本上是等价的，都是用来描述视频大小的参数。长度分辨率都相同的文件，体积不同，实际上就是码率不同。

码率也可以解读为单位时间内，用来记录视频的数据总量。码率越高的视频，意味着用来记录视频的数据量越多，潜在的解读就是视频可以拥有更好的质量。（注意，仅仅是潜在，后文我们会分析为什么高码率不一定等于高画质）

## 图像的表示方法

### RGB模型

光的三原色是红(Red)、绿(Green)、蓝(Blue)。现代的显示器技术就是通过组合不同强度的三原色，来达成任何一种可见光的颜色。图像储存中，通过记录每个像素红绿蓝强度，来记录图像的方法，称为RGB模型 (RGB Model)

常见的图片格式中，PNG和BMP这两种就是基于RGB模型的。



比如说原图：

![原图](//vcb-s.com/wp-content/uploads/2014/12/1111.jpg)

分别只显示R G B通道的强度，效果如下：

![RGB-R](//vcb-s.com/wp-content/uploads/2014/12/111.jpg)

![RGB-G](//vcb-s.com/wp-content/uploads/2014/12/1112.jpg)

![RGB-B](//vcb-s.com/wp-content/uploads/2014/12/1113.jpg)

三个通道下，信息量和细节程度不一定是均匀分布的。比如说可以注意南小鸟脸上的红晕，在3个平面上的区分程度就不同——红色平面下几乎无从区分，造成区别的主要是绿色和蓝色的平面。外围白色的脸颊，三色都近乎饱和；但是红晕部分，只有红色饱和，绿色和蓝色不饱和。这是造成红色凸显的原因。

## YUV模型

除了RGB模型，还有一种广泛采用的模型，称为YUV模型，又被称为亮度-色度模型（Luma-Chroma）。它是通过数学转换，将RGB三个通道，转换为一个代表亮度的通道(Y,又称为Luma)，和两个代表色度的通道(UV，并成为Chroma)。



YUV模型干的是类似的事儿。通过对RGB数据的合理转换，得到另一种表示方式。YUV模型下，还有不同的实现方式。举个用的比较多的YCbCr模型：它把RGB转换成一个亮度(Y)，和 蓝色色度(Cb) 以及 红色色度(Cr)。转换背后复杂的公式大家不需要了解，只需要看看效果：

只有亮度通道：

![YUV-Y](//vcb-s.com/wp-content/uploads/2014/12/1114.jpg)

只有蓝色色度：

![YUV-Cb](//vcb-s.com/wp-content/uploads/2014/12/1115.jpg)

只有红色色度：

![YUV-Cr](//vcb-s.com/wp-content/uploads/2014/12/1116.jpg)

在图像视频的加工与储存中，YUV格式一般更受欢迎，理由如下：



1. 人眼对亮度的敏感度远高于色度，因此人眼看到的有效信息主要来自于亮度。YUV模型可以将绝大多数的有效信息分配到Y通道。UV通道相对记录的信息少的多。相对于RGB模型较为平均的分配，YUV模型将多数有效信息集中在Y通道，不但减少了冗余信息量，还为压缩提供了便利

2. 保持了对黑白显示设备的向下兼容

3. 图像编辑中，调节亮度和颜色饱和度，在YUV模型下更方便。



几乎所有的视频格式，以及广泛使用的JPEG图像格式，都是基于YCbCr模型的。播放的时候，播放器需要将YCbCr的信息，通过计算，转换为RGB。这个步骤称为渲染（Rendering）

每个通道的记录，通常是用整数来表示。比如RGB24，就是RGB各8个bit，用0~255 (8bit的二进制数范围)来表示某个颜色的强弱。YUV模型也不例外，也是用整数来表示每个通道的高低。

## 色深

色深(bit-depth)，就是我们通常说的8bit和10bit，是指每个通道的精度。8bit就是每个通道用一个8bit整数`(0~255)`代表，10bit就是用10bit整数`(0~1023)`来显示。16bit则是`0~65535`

(注意，上文的表述是不严谨的，视频在编码的时候，并非一定能用到`0~255`的所有范围，而是可能有所保留，只用到一部分，比如`16~235`。这我们就不详细展开了)



你的显示器是8bit的，代表它能显示RGB每个通道0~255所有强度。但是视频的色深是YUV的色深，播放的时候，YUV需要通过计算转换到RGB。因此，10bit的高精度是间接的，它使得运算过程中精度增加，以让最后的颜色更细腻。

如何理解8bit显示器，播放10bit是有必要的呢：

一个圆的半径是12.33m, 求它的面积，保留两位小数。

半径的精度给定两位小数，结果也要求两位小数，那么圆周率精度需要给多高呢？也只要两位小数么？

取pi=3.14, 面积算出来是477.37平方米

取pi=3.1416，面积算出来是477.61平方米

取pi精度足够高，面积算出来是477.61平方米。所以取pi=3.1416是足够的，但是3.14就不够了。

换言之，即便最终输出的精度要求较低，也不意味着参与运算的数字，以及运算过程，可以保持较低的精度。在最终输出是8bit RGB的前提下，10bit YUV比起8bit YUV依旧具有精度优势的原因就在这里。事实上，8bit YUV转换后，覆盖的精度大概相当于8bit RGB的26%，而10bit转换后的精度大约可以覆盖97%——你想让你家8bit显示器发挥97%的细腻度么？看10bit吧。

8bit精度不足，主要表现在亮度较低的区域，容易形成色带

![色带](//vcb-s.com/wp-content/uploads/2013/11/logo11.png)

注意这图右边那一圈圈跟波浪一样的效果。这就是颜色精度不足的表现。

10bit的优势不只在于显示精度的提高，在提高视频压缩率，减少失真方面，相对8bit也有优势。这方面就不展开了。

## 帧、帧的类型V

电影是由多个“图片”连续播放组成的，每个“图片”被称为***帧***，电影单位时间内播放的帧的数目称为***帧率***，常见帧率数值有：**23.97、24、29.97**等等



相邻连续帧主要部分基本相同，画面中只有部分内容发生运动改变，因此可以对于相似帧只保存变换的内容，用于储存节约空间。



根据帧储存性质，可以分为3类：



**I帧(Intracoded帧)**:此帧是一个独立的帧，它不使用其前后的帧中的任何信息。一般作为参考帧的基础架构，储存完整的帧信息，占用空间较大。



**P帧（Predicted帧）**:P帧又称帧间预测编码帧，需要参考前面的I帧才能进行编码。表示的是当前帧画面与前一帧（前一帧可能是I帧也可能是P帧）的差别。解码时需要用之前缓存的画面叠加上本帧定义的差别，生成最终画面。与I帧相比，P帧通常占用更少的空间。



**B帧（Bi-predictive帧）**:B帧又称双向预测编码帧，也就是B帧记录的是本帧与前后帧的差别。也就是说要解码B帧，不仅要取得之前的缓存画面，还要解码之后的画面，通过前后画面的与本帧数据的叠加取得最终的画面。B帧压缩率高，但是对解码性能要求较高。



![I_P_and_B_frames](/Picture/I_P_and_B_frames.png)





不同编码根据自己算法，对于一个视频进行压缩编码，不同的编码方式，对于不同帧处理方式不同，有着自己的标准。



## 色度半采样

在YUV模型的应用中，Y和UV的重要性是不等同的。图像视频的实际储存和传输中，通常将Y以全分辨率记录，UV以减半甚至1/4的分辨率记录。这个手段被称为色度半采样(Chroma Sub-Sampling)。色度半采样可以有效减少传输带宽，和加大UV平面的压缩率，但是不可避免的会损失UV平面的有效信息。

我们平常的视频，最常见的是420采样。配合YUV格式，常常被写作yuv420。这种采样是Y保留全部，UV只以(1/2) x (1/2)的分辨率记录。比如说1920×1080的视频，其实只有亮度平面是1920×1080。两个色度平面都只有960×540的分辨率。

当然了，你也可以选择不做缩减。这种称为444采样，或者yuv444。YUV三个平面全是满分辨率。

在做YUV->RGB的时候，首先需要将缩水的UV分辨率拉升到Y的分辨率（madVR中允许自定义算法，在Chroma Upscaling当中），然后再转换到RGB。做RGB->YUV的转换，也是先转换到444（YUV的分辨率相同），再将UV分辨率降低。

一般能拿到的片源，包括所有蓝光原盘，都是420采样的。所以成品一般也保留420采样。所以yuv420就表示这个视频是420采样的yuv格式。

将420做成444格式，需要自己手动将UV分辨率拉升2×2倍。在今天madVR等渲染器可以很好地拉升UV平面的情况下，这种做法无异于毫无必要的拉升DVD做成伪高清。

当然了，有时候也需要在444/RGB平面下做处理和修复，常见的比如视频本身RGB平面不重叠（比如摩卡少女樱），这种修复过程首先要将UV分辨率拉升，然后转RGB，做完修复再转回YUV。修复后的结果相当于全新构图，这种情况下保留444格式就是有理由，有必要的。

H264格式编码444格式，需要High 4:4:4 Predictive Profile（简称Hi444pp）。所以看到Hi444pp/yuv444 之类的标示，你就需要去找压制者的陈述，为什么他要做这么个拉升。如果找不到有效的理由，你应该默认作者是在瞎做。

## 清晰度与画质简述

经常看到的说法：“这个视频清晰度是1080p的”。其实看过上文你就应该知道，1080p只是视频的分辨率，它不能直接代表清晰度——比如说，我可以把一个480p的dvd视频拉升到1080p，那又怎样呢？它的清晰度难道就提高了么？



视频的画质，是由以下几点共同决定的

1. <h6>源的画质。</h6>

俗话说的好，上梁不正下梁歪。如果源的画质本身很差，那么再如何折腾都别指望画质好到哪去。所以压制者往往会选择更好的源进行压制——举个栗子，BDRip一般都比TVRip来的好，哪怕是720p。蓝光也分销售地区，一般日本销售的日版，画质上比美版、台版、港版啥的都来得好，所以同样是BDRip，选取更好的源，就能做到画质上优先一步。



2. <h6>播放条件。</h6>

观众是否用了足矣支持高画质播放的硬件和软件。这就是为啥我们在发布Rip的同时大力普及好的播放器；有时候一个好的播放器胜过多少在制作方面的精力投入。



3. <h6>码率投入vs编码复杂度。</h6>

视频的时间和空间复杂度，并称为编码复杂度。编码复杂度高的视频，往往细节多，动态高（比如《魔法少女小圆剧场版 叛逆的物语》），这样的视频天生需要较高的码率去维持一个优秀的观看效果。

相反，有些视频编码复杂度低（比如《请问今天要来点兔子么》，动态少，线条细节柔和），这种视频就是比较节省码率的。



4. <h6>码率分配的效率和合理度。</h6>

同样多的码率，能起到怎样好的效果，被称为效率。比如H264就比之前的RealVideo效率高；10bit比8bit效率高；编码器先进，参数设置的比较合理，编码器各种高端参数全开（通常以编码时间作为代价），码率效率就高。

合理度就是码率在时空分配方面合理与否，合理的分配，给观众的观看效果就比较统一协调。 码率分配的效率和合理度，是对制作者的要求，要求制作者对片源分析，参数设置有比较到位的理解。

码率分配和合理度做的好，就常常能做出低码率高画质的良心作品。



5. 编码前的预处理。预处理分三种：

 1. 客观修复。强调修复片源固有的瑕疵，比如锯齿，色带，晕轮等等。

 2. 主观调整，强调将片源调整的更适合人眼观看，比如适度的锐化，调色（有时候你是可以通过科学方法判定片源的颜色有问题，然后针对的做修复的）。

 3. 移除无效高频信息，比如降噪，避免码率浪费在无效的噪点上

 

 预处理做的好，往往能达到画质上超越片源，或是在几乎不牺牲清晰度的前提下，节省码率开销。

 但是预处理是一把双刃剑，优化的同时，可能引入副效果。降噪、抗锯齿、去晕轮等操作会不可避免的损失一些有效细节（或多或少，取决于制作者水准）；主观调整很可能 会引入副效果（比如过度锐化会导致锯齿和晕轮），或是变成了作者的自我满足，形成对观众的欺骗。



综上，一个优秀的画质，是由片源、制作者、观看者共同决定的；码率高低也只是部分因素，并非决定性的效果。

